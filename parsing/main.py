"""
–ì–õ–ê–í–ù–´–ô –§–ê–ô–õ –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
========================

–õ–æ–≥–∏–∫–∞ —Ä–∞–±–æ—Ç—ã:
1. –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å Google Drive
2. –ü–∞—Ä—Å–∏—Ç Excel —Ñ–∞–π–ª—ã (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —Å—Ç—É–¥–µ–Ω—Ç–∞—Ö, –æ—Ü–µ–Ω–∫–∞—Ö, –¥–∞—Ç–∞—Ö)
3. –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª—è–µ–º—ã—Ö –≥—Ä—É–ø–ø
4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
5. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä—Å–∏–Ω–≥–µ –≤ —Ç–∞–±–ª–∏—Ü—É ParseLog
6. –í—ã–≤–æ–¥–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
7. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è —Ä–∞–∑ –≤ —á–∞—Å
   (–≤ 00 –º–∏–Ω—É—Ç –∫–∞–∂–¥–æ–≥–æ —á–∞—Å–∞)

–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞: main()
"""

import os
import sys
import re
import json
import schedule
import time
from datetime import datetime, timedelta

# –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É parsing –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from database import init_db, get_db, Group, Student, Subject, Grade, Topic, ParseLog
from downloaders.google_drive import download_target_files
from parsers.excel_parser import parse_excel_file
from logger import log_parser_info, log_parser_error


def save_to_database(parsed_data_per_file):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
    
    –õ–æ–≥–∏–∫–∞:
    1. –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –≥—Ä—É–ø–ø—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã
    2. –£–¥–∞–ª—è–µ—Ç –≤—Å–µ —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (–æ—Ü–µ–Ω–∫–∏, —Å—Ç—É–¥–µ–Ω—Ç–æ–≤, –ø—Ä–µ–¥–º–µ—Ç—ã) –¥–ª—è —ç—Ç–∏—Ö –≥—Ä—É–ø–ø
    3. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    db = get_db()
    try:
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å—Ç—É–¥–µ–Ω—Ç–∞–º–∏
        header_keywords = [
            '–º–µ—Å—è—Ü/—á–∏—Å–ª–æ', '—Ñ–∏–æ –æ–±—É—á–∞—é—â–∏—Ö—Å—è', '—Ñ–∏–æ', '–∫–æ–ª-–≤–æ —á–∞—Å–æ–≤', 
            '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤', '—á–∞—Å—ã', '—Å—Ç—É–¥–µ–Ω—Ç', '–æ–±—É—á–∞—é—â–∏–π—Å—è'
        ]
        
        def is_valid_student(fio):
            """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø–∏—Å—å –≤–∞–ª–∏–¥–Ω—ã–º —Å—Ç—É–¥–µ–Ω—Ç–æ–º"""
            if not fio:
                return False
            fio_lower = str(fio).lower().strip()
            if any(keyword in fio_lower for keyword in header_keywords):
                return False
            if len(fio_lower) < 3:
                return False
            return True
        
        # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≥—Ä—É–ø–ø—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã
        groups_to_update = set()
        groups_data = {}
        
        for file_name, all_data in parsed_data_per_file.items():
            if not all_data:
                continue
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≥—Ä—É–ø–ø–∞–º
            for item in all_data:
                group_name = item['group']
                groups_to_update.add(group_name)
                
                if group_name not in groups_data:
                    groups_data[group_name] = {}
                
                subject_name = item['subject']
                if subject_name not in groups_data[group_name]:
                    groups_data[group_name][subject_name] = []
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã (–≤–∫–ª—é—á–∞—è —Ç–µ–º—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ—Ç –§–ò–û)
                # –î–ª—è —Ç–µ–º –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ is_valid_student –Ω–µ –Ω—É–∂–Ω–∞
                if item.get('type') == 'topic' or item.get('type') == 'statistics' or is_valid_student(item.get('fio')):
                    groups_data[group_name][subject_name].append(item)
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª—è–µ–º—ã—Ö –≥—Ä—É–ø–ø
        for group_name in groups_to_update:
            group = db.query(Group).filter(Group.name == group_name).first()
            if group:
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –æ—Ü–µ–Ω–∫–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
                students_in_group = db.query(Student).filter(Student.group_id == group.id).all()
                for student in students_in_group:
                    db.query(Grade).filter(Grade.student_id == student.id).delete()
                
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≥—Ä—É–ø–ø—ã
                db.query(Student).filter(Student.group_id == group.id).delete()
                
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Ç–µ–º—ã –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –≥—Ä—É–ø–ø—ã
                subjects_in_group = db.query(Subject).filter(Subject.group_id == group.id).all()
                for subject in subjects_in_group:
                    db.query(Topic).filter(Topic.subject_id == subject.id).delete()
                
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–µ–¥–º–µ—Ç—ã –≥—Ä—É–ø–ø—ã
                db.query(Subject).filter(Subject.group_id == group.id).delete()
                
                # –£–¥–∞–ª—è–µ–º —Å–∞–º—É –≥—Ä—É–ø–ø—É
                db.delete(group)
        
        db.flush()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        for group_name, subjects_data in groups_data.items():
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
            group = Group(name=group_name)
            db.add(group)
            db.flush()
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –§–ò–û
            from parsers.excel_parser import normalize_fio_to_initials
            
            # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø—ã
            # –≠—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ–¥–º–µ—Ç–æ–≤, —á—Ç–æ–±—ã –Ω–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
            all_students_fio = set()
            for subject_name, items in subjects_data.items():
                for item in items:
                    fio = item.get('fio', '')
                    if fio:
                        fio_normalized = normalize_fio_to_initials(str(fio).strip())
                        if fio_normalized and len(fio_normalized) >= 3:
                            all_students_fio.add(fio_normalized)
            
            # –°–æ–∑–¥–∞–µ–º –≤—Å–µ—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≥—Ä—É–ø–ø—ã –æ–¥–∏–Ω —Ä–∞–∑
            students_map = {}  # –§–ò–û -> Student –æ–±—ä–µ–∫—Ç
            for fio_normalized in all_students_fio:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π —Å—Ç—É–¥–µ–Ω—Ç (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –ë–î –Ω–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞)
                existing_student = db.query(Student).filter(
                    Student.fio == fio_normalized,
                    Student.group_id == group.id
                ).first()
                
                if existing_student:
                    students_map[fio_normalized] = existing_student
                else:
                    student = Student(fio=fio_normalized, group_id=group.id)
                    db.add(student)
                    students_map[fio_normalized] = student
            
            db.flush()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –æ—Ü–µ–Ω–æ–∫
            
            # –¢–µ–ø–µ—Ä—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–µ–¥–º–µ—Ç—ã –∏ –æ—Ü–µ–Ω–∫–∏
            for subject_name, items in subjects_data.items():
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–µ–¥–º–µ—Ç
                subject = Subject(name=subject_name, group_id=group.id)
                db.add(subject)
                db.flush()
                
                # –û—Ç–¥–µ–ª—è–µ–º —Ç–µ–º—ã –æ—Ç –æ—Ü–µ–Ω–æ–∫ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                topics_items = [item for item in items if item.get('type') == 'topic']
                statistics_items = [item for item in items if item.get('type') == 'statistics']
                grades_items = [item for item in items if item.get('type') != 'topic' and item.get('type') != 'statistics' and item.get('fio')]
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–º—ã –∑–∞–Ω—è—Ç–∏–π
                for topic_item in topics_items:
                    topic_name = topic_item.get('topic', '').strip()
                    if topic_name and len(topic_name) >= 3:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è —Ç–µ–º–∞
                        existing_topic = db.query(Topic).filter(
                            Topic.subject_id == subject.id,
                            Topic.name == topic_name
                        ).first()
                        
                        if not existing_topic:
                            topic = Topic(
                                subject_id=subject.id,
                                name=topic_name,
                                hours=topic_item.get('hours', 2),
                                date=topic_item.get('date')
                            )
                            db.add(topic)
                
                db.flush()
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ü–µ–Ω–∫–∏ (—Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Ç–µ–º–∞–º–∏)
                for item in grades_items:
                    fio = item.get('fio', '')
                    date = item.get('date')
                    grade_value = item.get('grade', '')
                    
                    # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –°—Ç—Ä–æ–≥–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã
                    if not date:
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞—Ç–∞ –≤–∞–ª–∏–¥–Ω–∞ (–≥–æ–¥ >= 2000, –º–µ—Å—è—Ü 1-12, –¥–µ–Ω—å 1-31)
                    if hasattr(date, 'year'):
                        if date.year < 2000 or date.year > 2100:
                            continue
                        if date.month < 1 or date.month > 12:
                            continue
                        if date.day < 1 or date.day > 31:
                            continue
                    else:
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Ü–µ–Ω–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è
                    if not grade_value or str(grade_value).strip() == '':
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –§–ò–û –Ω–µ –ø—É—Å—Ç–æ–µ
                    if not fio or str(fio).strip() == '':
                        continue
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –§–ò–û –≤ —Ñ–æ—Ä–º–∞—Ç "–§–∞–º–∏–ª–∏—è –ò.–û."
                    fio_normalized = normalize_fio_to_initials(str(fio).strip())
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –§–ò–û –≤–∞–ª–∏–¥–Ω–æ
                    if not fio_normalized or len(fio_normalized) < 3:
                        continue
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—É–¥–µ–Ω—Ç–∞ –∏–∑ —Å–ª–æ–≤–∞—Ä—è (–æ–Ω —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω)
                    student = students_map.get(fio_normalized)
                    if not student:
                        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω (–Ω–µ –¥–æ–ª–∂–µ–Ω —Å–ª—É—á–∏—Ç—å—Å—è)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –æ—Ü–µ–Ω–∫–∞ (–Ω–∞ —Å–ª—É—á–∞–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
                    existing_grade = db.query(Grade).filter(
                        Grade.student_id == student.id,
                        Grade.subject_id == subject.id,
                        Grade.date == date
                    ).first()
                    
                    if not existing_grade:
                        # –°–æ–∑–¥–∞–µ–º –æ—Ü–µ–Ω–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—ë –µ—â–µ –Ω–µ—Ç
                        grade = Grade(
                            student_id=student.id,
                            subject_id=subject.id,
                            date=date,
                            value=str(grade_value)
                        )
                        db.add(grade)
        
        db.commit()
    except Exception as e:
        db.rollback()
    finally:
        db.close()


def parse_and_save():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    
    –õ–æ–≥–∏–∫–∞ —Ä–∞–±–æ—Ç—ã:
    1. –°–∫–∞—á–∏–≤–∞–µ—Ç –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å Google Drive
    2. –ü–∞—Ä—Å–∏—Ç Excel —Ñ–∞–π–ª—ã
    3. –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—ã–µ –≤ –ë–î
    4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä—Å–∏–Ω–≥–µ –≤ —Ç–∞–±–ª–∏—Ü—É ParseLog
    """
    parse_start_time = datetime.now()
    files_processed = 0
    groups_updated_list = []
    status = "success"
    error_message = None
    
    try:
        print("=" * 60, flush=True)
        print(f"üîÑ [PARSER] –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {parse_start_time.strftime('%Y-%m-%d %H:%M:%S')}", flush=True)
        print("=" * 60, flush=True)
        log_parser_info(
            "–ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞",
            "–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Excel —Ñ–∞–π–ª–æ–≤ —Å Google Drive"
        )
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã
        print("üì• [PARSER] –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ —Å Google Drive...", flush=True)
        downloaded_files = download_target_files()
        
        if not downloaded_files:
            status = "error"
            error_message = "–§–∞–π–ª—ã –Ω–µ –±—ã–ª–∏ —Å–∫–∞—á–∞–Ω—ã"
            print("‚ùå [PARSER] –§–∞–π–ª—ã –Ω–µ –±—ã–ª–∏ —Å–∫–∞—á–∞–Ω—ã", flush=True)
            log_parser_error(
                "–§–∞–π–ª—ã –Ω–µ –±—ã–ª–∏ —Å–∫–∞—á–∞–Ω—ã",
                description="–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª—ã —Å Google Drive"
            )
            return
        
        print(f"‚úÖ [PARSER] –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(downloaded_files)}", flush=True)
        for f in downloaded_files:
            print(f"   üìÑ [PARSER] - {os.path.basename(f)}", flush=True)
        log_parser_info(
            f"–°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(downloaded_files)}",
            f"–§–∞–π–ª—ã: {', '.join([os.path.basename(f) for f in downloaded_files])}"
        )
        
        # –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª—ã
        print("üìä [PARSER] –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ Excel —Ñ–∞–π–ª–æ–≤...", flush=True)
        parsed_data_per_file = {}
        for file_path in downloaded_files:
            try:
                file_name = os.path.basename(file_path)
                print(f"   üîç [PARSER] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file_name}...", flush=True)
                log_parser_info(
                    f"–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞: {file_name}",
                    f"–û–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–∞"
                )
                
                data = parse_excel_file(file_path)
                parsed_data_per_file[file_name] = data
                files_processed += 1
                
                print(f"   ‚úÖ [PARSER] –§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {file_name} (–∑–∞–ø–∏—Å–µ–π: {len(data)})", flush=True)
                log_parser_info(
                    f"–§–∞–π–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {file_name}",
                    f"–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(data)}"
                )
            except Exception as e:
                error_message = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {file_path}: {str(e)}"
                log_parser_error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {os.path.basename(file_path)}",
                    error=e,
                    description=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Ñ–∞–π–ª: {file_path}"
                )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
        if parsed_data_per_file:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø
            groups_updated_list = list(set(
                item.get('group') 
                for file_data in parsed_data_per_file.values() 
                for item in file_data 
                if item.get('group')
            ))
            
            print(f"üíæ [PARSER] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î...", flush=True)
            print(f"   üë• [PARSER] –ì—Ä—É–ø–ø –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(groups_updated_list)}", flush=True)
            if groups_updated_list:
                print(f"   üìã [PARSER] –ì—Ä—É–ø–ø—ã: {', '.join(groups_updated_list)}", flush=True)
            log_parser_info(
                f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î",
                f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø: {', '.join(groups_updated_list) if groups_updated_list else '–Ω–µ—Ç'}"
            )
            
            save_to_database(parsed_data_per_file)
            
            print(f"‚úÖ [PARSER] –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î", flush=True)
            log_parser_info(
                f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î",
                f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –≥—Ä—É–ø–ø: {len(groups_updated_list)}"
            )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä—Å–∏–Ω–≥–µ –≤ —Ç–∞–±–ª–∏—Ü—É
        db = get_db()
        try:
            parse_log = ParseLog(
                parse_time=parse_start_time,
                files_processed=files_processed,
                groups_updated=json.dumps(groups_updated_list, ensure_ascii=False) if groups_updated_list else None,
                status=status,
                error_message=error_message
            )
            db.add(parse_log)
            db.commit()
        except Exception as e:
            db.rollback()
        finally:
            db.close()
        
        # –í—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
        parse_end_time = datetime.now()
        duration = (parse_end_time - parse_start_time).total_seconds()
        groups_str = ", ".join(groups_updated_list) if groups_updated_list else "–Ω–µ—Ç"
        
        log_parser_info(
            "–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ",
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {files_processed}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ –≥—Ä—É–ø–ø: {len(groups_updated_list)}, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.2f} —Å–µ–∫",
            details={
                "files_processed": files_processed,
                "groups_count": len(groups_updated_list),
                "groups": groups_updated_list,
                "duration_seconds": duration
            }
        )
        
        print("=" * 60, flush=True)
        print(f"‚úÖ [PARSER] –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!", flush=True)
        print(f"   üìÖ [PARSER] –í—Ä–µ–º—è: {parse_end_time.strftime('%Y-%m-%d %H:%M:%S')}", flush=True)
        print(f"   ‚è±Ô∏è  [PARSER] –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.2f} —Å–µ–∫", flush=True)
        print(f"   üìÅ [PARSER] –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {files_processed}", flush=True)
        print(f"   üë• [PARSER] –ì—Ä—É–ø–ø –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {len(groups_updated_list)} ({groups_str})", flush=True)
        print(f"   üíæ [PARSER] –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î", flush=True)
        print("=" * 60, flush=True)
        print("", flush=True)
        
    except KeyboardInterrupt:
        status = "error"
        error_message = "–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º"
        log_parser_error(
            "–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
            description="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Å—Ç–∞–Ω–æ–≤–∏–ª –ø—Ä–æ—Ü–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞"
        )
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
        db = get_db()
        try:
            parse_log = ParseLog(
                parse_time=parse_start_time,
                files_processed=files_processed,
                groups_updated=None,
                status=status,
                error_message=error_message
            )
            db.add(parse_log)
            db.commit()
        except Exception:
            db.rollback()
        finally:
            db.close()
    except Exception as e:
        status = "error"
        error_message = str(e)
        log_parser_error(
            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {error_message}",
            error=e,
            description="–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–∞—Ä—Å–∏–Ω–≥–∞"
        )
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
        db = get_db()
        try:
            parse_log = ParseLog(
                parse_time=parse_start_time,
                files_processed=files_processed,
                groups_updated=None,
                status=status,
                error_message=error_message
            )
            db.add(parse_log)
            db.commit()
        except Exception:
            db.rollback()
        finally:
            db.close()
        print("=" * 60, flush=True)
        print(f"‚ùå [PARSER] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {error_message}", flush=True)
        print("=" * 60, flush=True)
        print("", flush=True)


def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    
    –õ–æ–≥–∏–∫–∞:
    1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    2. –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞
    3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ä–∞–∑ –≤ —á–∞—Å
       (–≤ 00 –º–∏–Ω—É—Ç –∫–∞–∂–¥–æ–≥–æ —á–∞—Å–∞)
    4. –ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
    """
    init_db()
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ä–∞–∑—É (–±–µ–∑ –≤—ã–≤–æ–¥–∞)
    parse_and_save()
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ —Ä–∞–∑ –≤ —á–∞—Å
    # –ó–∞–ø—É—Å–∫ –≤ 00 –º–∏–Ω—É—Ç –∫–∞–∂–¥–æ–≥–æ —á–∞—Å–∞
    schedule.every().hour.at(":00").do(parse_and_save)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
    while True:
        schedule.run_pending()
        time.sleep(60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É


if __name__ == "__main__":
    main()
